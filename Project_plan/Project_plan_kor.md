# 프로젝트 계획: 가상 기술 전문가 및 R&D 가속화 시스템

## 1. 프로젝트 개요 (Project Overview)

* **프로젝트명**: 가상 기술 전문가 R&D 시스템 (VTE-R&D)
* **목표**: 사용자가 RAG 기반의 가상 전문가를 즉시 생성하여 기술적 주제에 대해 토론시키고, 그 결과로 심층적인 연구 보고서를 도출하는 Multi-Agent 시스템 구축.
* **핵심 가치**: 로컬/클라우드 LLM과 실시간 데이터를 결합한 AI 집단 지성을 활용하여, R&D 과정에서의 물리적/시간적 제약을 극복.

## 2. 문제점 및 해결책 (Problem & Solution)

* **문제점 (Problem)**: 새로운 기술 분야 탐색 시 발생하는 과도한 문헌 검토 시간, 외부 전문가 섭외의 어려움, 지속적인 기술 가설 검증의 필요성.
* **해결책 (Solution)**:
  * **온디맨드 지식 (On-demand Knowledge)**: RAG를 통한 전문가 에이전트의 즉각적인 생성.
  * **맥락 인식 (Context-Aware)**: 실시간 데이터 수집(논문: OpenAlex, 특허: EPO)을 통한 깊이 있는 기술적 맥락 확보.
  * **다각적 분석 (Multi-Perspective)**: 다양한 페르소나 간의 시뮬레이션 토론을 통한 입체적 인사이트 도출.

## 3. 시스템 아키텍처 및 기술 스택

### 3.1. 상위 레벨 아키텍처

1. **Layer 1 (데이터 수집)**: 외부 API(OpenAlex, EPO OPS) 연동 및 Raw Data 수집.
2. **Layer 2 (인텔리전스 엔진)**: 고속 클러스터링 및 데이터 정제/선별.
3. **Layer 3 (에이전트 코어)**: 로컬/클라우드 LLM 추론 및 토론 오케스트레이션.

### 3.2. 기술 사양 (Strict Constraints)

시스템은 반드시 아래 명시된 모델과 라이브러리를 사용해야 합니다.

* **언어**: Python 3.10+
* **LLM 추론 (Ollama 지원 필수)**:
  * **기본 모델 (Local)**: `deepseek-r1:14b` (Ollama Local 실행)
  * **대체 모델 (Cloud)**: `gpt-oss:120b-cloud` (Ollama Cloud 엔드포인트)
  * *설정*: `.env` 파일을 통해 로컬과 클라우드 엔드포인트를 쉽게 전환할 수 있어야 함.
* **임베딩 모델 (Embedding)**:
  * **모델**: `nomic-embed-text:latest` (Ollama 구동)
* **클러스터링 모델 (고속 군집화)**:
  * **알고리즘**: **Mini-Batch K-Means** (Scikit-learn 사용).
  * **선택 이유**: 일반 K-Means나 DBSCAN 대비 대량의 데이터 세트에서 압도적인 처리 속도 제공.
* **Vector DB**: ChromaDB (로컬) 또는 Milvus.
* **오케스트레이션**: LangGraph (순환형 토론 흐름 구현에 최적화).
* **데이터 API**:
  * **논문**: OpenAlex API.
  * **특허**: **EPO OPS (유럽특허청 Open Patent Services) API**.

---

## 4. 상세 워크플로우 및 로직

### Step 1: 쿼리 확장 및 데이터 수집

* **입력**: 사용자의 자연어 키워드/문장.
* **프로세스**:
    1. **LLM 에이전트**: `deepseek-r1:14b`를 사용하여 검색용 Boolean 검색식 생성.
    2. **API 핸들러**: 약 1,000건의 관련 문헌 수집.
        * **Source A**: OpenAlex (학술 논문).
        * **Source B**: **EPO OPS API (특허)**.

### Step 2: 고속 데이터 정제 (Intelligence Engine)

* **벡터화**: `nomic-embed-text:latest`를 사용하여 수집된 데이터의 제목/초록을 벡터로 변환.
* **고속 클러스터링 (Mini-Batch K-Means)**:
  * 벡터화된 데이터를 즉시 군집화하여 하위 기술 주제 식별.
  * **노이즈 제거**: 사용자 쿼리 벡터와 거리가 먼 군집은 자동 제거.
* **선별**: 군집 중심점(Centroid)에 가까운 핵심 문헌 약 100~200건 최종 선별.

### Step 3: 지식 주입 (RAG Setup)

* **인덱싱**: 선별된 데이터를 청킹하여 Vector DB에 저장 (임베딩: `nomic-embed-text:latest`).
* **메타데이터**: 클러스터 ID 및 소스 유형(논문/특허)을 태깅하여 전문가별 전문성 부여.

---

## 5. 다중 에이전트 페르소나 라이브러리

*모든 에이전트는 기본적으로 `deepseek-r1:14b` 모델을 사용합니다.*

| 페르소나 ID | 이름 | 역할 및 행동 지침 |
| :--- | :--- | :--- |
| **P_OPT** | **기술 낙관론자** | 혁신성과 확장성에 집중. 사소한 비용보다 기술적 돌파구를 강조. |
| **P_SKEP** | **시장 회의론자** | ROI, 현실적 규제, 시장 채택의 한계 및 실패 가능성에 집중. |
| **P_COMP** | **경쟁사 빙의** | 경쟁사의 입장에서 기술적 약점을 파고들고 대응 전략을 분석. |
| **P_REG** | **규제 감시자** | 법적 리스크, 안전 표준, 환경 규제 및 윤리적 이슈 점검. |
| **P_MOD** | **R&D 마에스트로** | 토론을 중재하고 각 의견을 종합하여 최종 결론 및 보고서 작성. |

---

## 6. 토론 시뮬레이션 모드 (구현 로직)

### Mode A: 단계적 검증 (Sequential Verification)

* **흐름**: `낙관론자(P_OPT)` 주장 -> `회의론자(P_SKEP)` 반박 -> `사회자(P_MOD)` 결론.
* **구현**: LangGraph를 이용한 선형 체인(Linear Chain) 방식.

### Mode B: 병렬 토론 후 종합 (Parallel & Converge)

* **흐름**:
  * 트랙 1: `낙관론자` vs `경쟁사` (기술성 평가)
  * 트랙 2: `회의론자` vs `규제감시자` (사업성 평가)
  * 병합: `사회자`가 양쪽 트랙을 요약하여 종합 보고서 작성.

### Mode C: 합의 도출 모델 (Iterative Refinement)

* **흐름**:
    1. `낙관론자`가 초안 제안.
    2. 다른 모든 전문가가 비판적 피드백 제공.
    3. 비판 수용도가 낮을 경우 `낙관론자`가 초안 수정 후 루프 재진입.
    4. 전원 합의 또는 최대 턴 도달 시 종료.

---

## 7. 개발 로드맵 (코드 생성 가이드)

### Phase 1: 환경 및 모델 설정

* `OllamaClient` 클래스 구축 (`deepseek-r1:14b` 및 `nomic-embed-text:latest` 처리).
* `DataProcessor` 클래스 내 `MiniBatchKMeans` 로직 구현.

### Phase 2: 데이터 파이프라인

* `OpenAlexFetcher` 구현.
* **`EPOPatentFetcher`** 구현 (EPO OPS API 사용).
* [임베딩 - 클러스터링 - 필터링]으로 이어지는 파이프라인 통합.

### Phase 3: 에이전트 그래프 (LangGraph)

* 각 페르소나별 프롬프트 템플릿 정의.
* 3가지 토론 모드를 개별 그래프 워크플로우로 구현.

### Phase 4: 보고서 생성 및 UI

* 토론 이력을 마크다운 형식의 보고서로 변환하는 `ReportGenerator` 구현.
* 결과를 확인할 수 있는 CLI 또는 Streamlit 대시보드 구축.
